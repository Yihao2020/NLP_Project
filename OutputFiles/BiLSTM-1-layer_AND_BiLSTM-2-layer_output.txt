2021-04-21 12:24:44.391631: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-04-21 12:24:44.391672: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-04-21 12:24:46.413869: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-21 12:24:46.414704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-21 12:24:49.038983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-21 12:24:49.039843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-21 12:24:49.040689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties:
pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-21 12:24:49.041512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties:
pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-21 12:24:49.041664: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.041789: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.041907: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042025: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042144: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042262: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042384: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042500: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-04-21 12:24:49.042513: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-04-21 12:24:49.042799: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-21 12:24:49.043343: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-21 12:24:49.043365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-21 12:24:49.043372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
2021-04-21 12:28:01.584199: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 35294208000 exceeds 10% of free system memory.
2021-04-21 12:28:19.263273: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-21 12:28:19.316575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3597840000 Hz


-------------------------------------------------   BILSTM 1 LAYER   ---------------------------------------------------




Model: "bilstm_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 100, 768)]        0
_________________________________________________________________
bidirectional (Bidirectional (None, 100, 140)          469840
_________________________________________________________________
flatten (Flatten)            (None, 14000)             0
_________________________________________________________________
dense (Dense)                (None, 6)                 84006
=================================================================
Total params: 553,846
Trainable params: 553,846
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/10
3591/3591 [==============================] - 204s 54ms/step - loss: 0.1194 - tp: 2690.2102 - fp: 28704.5910 - tn: 303542.1306 - fn: 9990.9413 - accuracy: 0.8911 - precision: 0.0835 - recall: 0.1961 - auc: 0.7544 - prc: 0.0817 - val_loss: 0.0984 - val_tp: 962.0000 - val_fp: 10353.0000 - val_tn: 63342.0000 - val_fn: 1939.0000 - val_accuracy: 0.8395 - val_precision: 0.0850 - val_recall: 0.3316 - val_auc: 0.7571 - val_prc: 0.0864
Epoch 2/10
3591/3591 [==============================] - 192s 54ms/step - loss: 0.0951 - tp: 3816.5476 - fp: 34573.3235 - tn: 297701.0949 - fn: 8836.9070 - accuracy: 0.8734 - precision: 0.0997 - recall: 0.3053 - auc: 0.7511 - prc: 0.0922 - val_loss: 0.0950 - val_tp: 800.0000 - val_fp: 6218.0000 - val_tn: 67477.0000 - val_fn: 2101.0000 - val_accuracy: 0.8914 - val_precision: 0.1140 - val_recall: 0.2758 - val_auc: 0.7431 - val_prc: 0.1098
Epoch 3/10
3591/3591 [==============================] - 190s 53ms/step - loss: 0.0857 - tp: 3997.7439 - fp: 33966.6114 - tn: 298380.8853 - fn: 8582.6325 - accuracy: 0.8768 - precision: 0.1032 - recall: 0.3086 - auc: 0.7469 - prc: 0.1005 - val_loss: 0.0930 - val_tp: 1051.0000 - val_fp: 9223.0000 - val_tn: 64472.0000 - val_fn: 1850.0000 - val_accuracy: 0.8554 - val_precision: 0.1023 - val_recall: 0.3623 - val_auc: 0.7428 - val_prc: 0.0920
Epoch 4/10
3591/3591 [==============================] - 190s 53ms/step - loss: 0.0784 - tp: 4390.6523 - fp: 33934.3589 - tn: 298398.3394 - fn: 8204.5226 - accuracy: 0.8785 - precision: 0.1145 - recall: 0.3466 - auc: 0.7442 - prc: 0.1131 - val_loss: 0.0928 - val_tp: 1006.0000 - val_fp: 8770.0000 - val_tn: 64925.0000 - val_fn: 1895.0000 - val_accuracy: 0.8608 - val_precision: 0.1029 - val_recall: 0.3468 - val_auc: 0.7362 - val_prc: 0.0957
Epoch 5/10
3591/3591 [==============================] - 192s 54ms/step - loss: 0.0708 - tp: 4602.3792 - fp: 35407.8040 - tn: 296843.7940 - fn: 8073.8959 - accuracy: 0.8720 - precision: 0.1142 - recall: 0.3690 - auc: 0.7388 - prc: 0.1200 - val_loss: 0.0976 - val_tp: 1094.0000 - val_fp: 8333.0000 - val_tn: 65362.0000 - val_fn: 1807.0000 - val_accuracy: 0.8676 - val_precision: 0.1160 - val_recall: 0.3771 - val_auc: 0.7048 - val_prc: 0.1155
Epoch 6/10
3591/3591 [==============================] - 192s 53ms/step - loss: 0.0654 - tp: 4646.4126 - fp: 34499.7748 - tn: 297891.7906 - fn: 7889.8950 - accuracy: 0.8785 - precision: 0.1209 - recall: 0.3677 - auc: 0.7334 - prc: 0.1279 - val_loss: 0.1000 - val_tp: 1030.0000 - val_fp: 8636.0000 - val_tn: 65059.0000 - val_fn: 1871.0000 - val_accuracy: 0.8628 - val_precision: 0.1066 - val_recall: 0.3550 - val_auc: 0.7293 - val_prc: 0.0919
Epoch 7/10
3591/3591 [==============================] - 190s 53ms/step - loss: 0.0594 - tp: 4741.3950 - fp: 35992.5078 - tn: 296436.4685 - fn: 7757.5017 - accuracy: 0.8734 - precision: 0.1153 - recall: 0.3755 - auc: 0.7361 - prc: 0.1213 - val_loss: 0.1041 - val_tp: 948.0000 - val_fp: 7418.0000 - val_tn: 66277.0000 - val_fn: 1953.0000 - val_accuracy: 0.8777 - val_precision: 0.1133 - val_recall: 0.3268 - val_auc: 0.7138 - val_prc: 0.0935
Epoch 8/10
3591/3591 [==============================] - 190s 53ms/step - loss: 0.0554 - tp: 4975.3193 - fp: 35997.2030 - tn: 296278.7982 - fn: 7676.5526 - accuracy: 0.8731 - precision: 0.1217 - recall: 0.3959 - auc: 0.7316 - prc: 0.1304 - val_loss: 0.1108 - val_tp: 1182.0000 - val_fp: 10611.0000 - val_tn: 63084.0000 - val_fn: 1719.0000 - val_accuracy: 0.8390 - val_precision: 0.1002 - val_recall: 0.4074 - val_auc: 0.7168 - val_prc: 0.0875
Epoch 9/10
3591/3591 [==============================] - 192s 54ms/step - loss: 0.0516 - tp: 5016.9474 - fp: 37275.1242 - tn: 295011.9886 - fn: 7623.8129 - accuracy: 0.8688 - precision: 0.1185 - recall: 0.3976 - auc: 0.7278 - prc: 0.1256 - val_loss: 0.1111 - val_tp: 1035.0000 - val_fp: 7887.0000 - val_tn: 65808.0000 - val_fn: 1866.0000 - val_accuracy: 0.8727 - val_precision: 0.1160 - val_recall: 0.3568 - val_auc: 0.6886 - val_prc: 0.0946
2021-04-21 12:57:17.885097: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.
Restoring model weights from the end of the best epoch.
Epoch 00009: early stopping

-----------Evalution Results on Test Data---------------------
998/998 [==============================] - 21s 21ms/step - loss: 0.0937 - tp: 2604.0000 - fp: 21038.0000 - tn: 163471.0000 - fn: 4377.0000 - accuracy: 0.8673 - precision: 0.1101 - recall: 0.3730 - auc: 0.6956 - prc: 0.1123

2021-04-21 13:05:02.390232: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 35294208000 exceeds 10% of free system memory.

               precision    recall  f1-score   support

        toxic       0.11      0.83      0.20      3064
 severe toxic       0.02      0.01      0.01       331
      obscene       0.08      0.03      0.05      1697
       threat       0.00      0.00      0.00        96
       insult       0.01      0.00      0.00      1536
identity hate       0.02      0.02      0.02       257




-------------------------------------------------   BILSTM 2 LAYER   ---------------------------------------------------



Model: "bilstm_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         [(None, 100, 768)]        0
_________________________________________________________________
bidirectional_1 (Bidirection (None, 100, 140)          469840
_________________________________________________________________
bidirectional_2 (Bidirection (None, 20)                12080
_________________________________________________________________
flatten_1 (Flatten)          (None, 20)                0
_________________________________________________________________
dense_1 (Dense)              (None, 6)                 126
=================================================================
Total params: 482,046
Trainable params: 482,046
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/10
3591/3591 [==============================] - 354s 90ms/step - loss: 0.1329 - tp: 1868.2063 - fp: 22002.7522 - tn: 310377.1069 - fn: 10679.8076 - accuracy: 0.9185 - precision: 0.0787 - recall: 0.1210 - auc: 0.7445 - prc: 0.0793 - val_loss: 0.1033 - val_tp: 914.0000 - val_fp: 11077.0000 - val_tn: 62618.0000 - val_fn: 1987.0000 - val_accuracy: 0.8294 - val_precision: 0.0762 - val_recall: 0.3151 - val_auc: 0.7614 - val_prc: 0.0814
Epoch 2/10
3591/3591 [==============================] - 310s 86ms/step - loss: 0.0964 - tp: 3634.1899 - fp: 47272.6943 - tn: 285216.7010 - fn: 8804.2879 - accuracy: 0.8383 - precision: 0.0692 - recall: 0.2833 - auc: 0.7623 - prc: 0.0762 - val_loss: 0.0959 - val_tp: 1233.0000 - val_fp: 11423.0000 - val_tn: 62272.0000 - val_fn: 1668.0000 - val_accuracy: 0.8291 - val_precision: 0.0974 - val_recall: 0.4250 - val_auc: 0.7543 - val_prc: 0.0835
Epoch 3/10
3591/3591 [==============================] - 295s 82ms/step - loss: 0.0885 - tp: 4740.9852 - fp: 49889.6336 - tn: 282563.5181 - fn: 7733.7361 - accuracy: 0.8324 - precision: 0.0859 - recall: 0.3767 - auc: 0.7578 - prc: 0.0771 - val_loss: 0.0902 - val_tp: 1231.0000 - val_fp: 11390.0000 - val_tn: 62305.0000 - val_fn: 1670.0000 - val_accuracy: 0.8295 - val_precision: 0.0975 - val_recall: 0.4243 - val_auc: 0.7631 - val_prc: 0.0930
Epoch 4/10
3591/3591 [==============================] - 295s 82ms/step - loss: 0.0843 - tp: 5181.0699 - fp: 50682.7984 - tn: 281655.8820 - fn: 7408.1228 - accuracy: 0.8313 - precision: 0.0935 - recall: 0.4136 - auc: 0.7554 - prc: 0.0827 - val_loss: 0.0866 - val_tp: 1253.0000 - val_fp: 11418.0000 - val_tn: 62277.0000 - val_fn: 1648.0000 - val_accuracy: 0.8294 - val_precision: 0.0989 - val_recall: 0.4319 - val_auc: 0.7594 - val_prc: 0.0856
Epoch 5/10
3591/3591 [==============================] - 294s 82ms/step - loss: 0.0793 - tp: 5269.8970 - fp: 51244.5768 - tn: 281111.5234 - fn: 7301.8758 - accuracy: 0.8302 - precision: 0.0928 - recall: 0.4186 - auc: 0.7556 - prc: 0.0821 - val_loss: 0.0865 - val_tp: 1275.0000 - val_fp: 11468.0000 - val_tn: 62227.0000 - val_fn: 1626.0000 - val_accuracy: 0.8291 - val_precision: 0.1001 - val_recall: 0.4395 - val_auc: 0.7565 - val_prc: 0.0819
Epoch 6/10
3591/3591 [==============================] - 294s 82ms/step - loss: 0.0753 - tp: 5350.7536 - fp: 51389.9502 - tn: 281057.6648 - fn: 7129.5045 - accuracy: 0.8303 - precision: 0.0943 - recall: 0.4323 - auc: 0.7581 - prc: 0.0859 - val_loss: 0.0865 - val_tp: 1277.0000 - val_fp: 11454.0000 - val_tn: 62241.0000 - val_fn: 1624.0000 - val_accuracy: 0.8293 - val_precision: 0.1003 - val_recall: 0.4402 - val_auc: 0.7547 - val_prc: 0.0899
Epoch 7/10
3591/3591 [==============================] - 295s 82ms/step - loss: 0.0734 - tp: 5366.4193 - fp: 51459.8834 - tn: 280842.3299 - fn: 7259.2405 - accuracy: 0.8298 - precision: 0.0937 - recall: 0.4253 - auc: 0.7544 - prc: 0.0875 - val_loss: 0.0839 - val_tp: 1261.0000 - val_fp: 11375.0000 - val_tn: 62320.0000 - val_fn: 1640.0000 - val_accuracy: 0.8301 - val_precision: 0.0998 - val_recall: 0.4347 - val_auc: 0.7562 - val_prc: 0.1280
Epoch 8/10
3591/3591 [==============================] - 295s 82ms/step - loss: 0.0706 - tp: 5342.9059 - fp: 51216.0629 - tn: 281031.3101 - fn: 7337.5941 - accuracy: 0.8300 - precision: 0.0947 - recall: 0.4200 - auc: 0.7502 - prc: 0.0912 - val_loss: 0.0941 - val_tp: 1276.0000 - val_fp: 11432.0000 - val_tn: 62263.0000 - val_fn: 1625.0000 - val_accuracy: 0.8295 - val_precision: 0.1004 - val_recall: 0.4398 - val_auc: 0.7507 - val_prc: 0.1196
Epoch 9/10
3591/3591 [==============================] - 296s 82ms/step - loss: 0.0685 - tp: 5404.4190 - fp: 51309.9847 - tn: 280903.5217 - fn: 7309.9477 - accuracy: 0.8300 - precision: 0.0958 - recall: 0.4255 - auc: 0.7513 - prc: 0.1011 - val_loss: 0.0944 - val_tp: 1273.0000 - val_fp: 11432.0000 - val_tn: 62263.0000 - val_fn: 1628.0000 - val_accuracy: 0.8295 - val_precision: 0.1002 - val_recall: 0.4388 - val_auc: 0.7537 - val_prc: 0.1254
Epoch 10/10
3591/3591 [==============================] - 298s 83ms/step - loss: 0.0644 - tp: 5371.6253 - fp: 51372.5546 - tn: 280968.4209 - fn: 7215.2723 - accuracy: 0.8301 - precision: 0.0936 - recall: 0.4261 - auc: 0.7476 - prc: 0.1049 - val_loss: 0.0865 - val_tp: 1269.0000 - val_fp: 11351.0000 - val_tn: 62344.0000 - val_fn: 1632.0000 - val_accuracy: 0.8305 - val_precision: 0.1006 - val_recall: 0.4374 - val_auc: 0.7504 - val_prc: 0.0956
/home/devesh/NLP_project/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/devesh/NLP_project/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.
Evalution Results on Test Data

-----------Test DATA Results-----------

998/998 [==============================] - 25s 25ms/step - loss: 0.0826 - tp: 3018.0000 - fp: 28495.0000 - tn: 156014.0000 - fn: 3963.0000 - accuracy: 0.8305 - precision: 0.0958 - recall: 0.4323 - auc: 0.7488 - prc: 0.0925


/home/devesh/NLP_project/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/devesh/NLP_project/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/devesh/NLP_project/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/devesh/NLP_project/BiLSTM3.py:88: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
  plt.subplot(2, 2, n + 1)

               precision    recall  f1-score   support

        toxic       0.10      0.98      0.17      3064
 severe toxic       0.00      0.00      0.00       331
      obscene       1.00      0.00      0.00      1697
       threat       0.00      0.00      0.00        96
       insult       0.00      0.00      0.00      1536
identity hate       0.00      0.00      0.00       257